# 알고리즘

## 기초 알고리즘
### 1. 재귀 호출과 반복
#### 재귀 호출(Recursive call)
- 함수가 자기 사진을 호출하는 것
- 분할 정복(Divide & Conquer), 점화식 등을 구현하는데에 많이 사용
- 재귀 구현은 항상 반복 구현으로 변환 가능

#### 점화식(Recurrence relation)
- 재귀식(Recursion relation), 수열의 항 사이의 관계
- 점화식으로 표현된 수열을 n에 대한 식으로 표현 = 풀이한다(solve)
- 풀이한 결과 = 일반 식
- 대표적 점화식 예시
    - 피보나치 수열 : 𝑓(𝑛) = 𝑓(𝑛-1) + 𝑓(𝑛-2)
    - 팩토리얼 : 𝑓(𝑛) = 𝑛 × 𝑓(𝑛-1)
    - 등차 수열 : 𝑓(𝑛) - 𝑓(𝑛-1) = 𝑑
    - 등비 수열 : 𝑓(𝑛)/𝑓(𝑛-1) = 𝑟

#### 재귀 함수의 구현
- 재귀 호출 시 반드시 탈출 조건 필요
    - 탈출 조건 미 존재 시 재귀 호출은 무한히 계속됨.
- 점화식에 의거하여 재귀 호출 시행
    - 입력 파라미터를 달리해 결국 탈출 조건에 도달
```python
def fibonacci(n):
    if n < 2: # 탈출 조건
        return n
    return fibonacci(n-1) + fibonacci(n-2) # 재귀 호출(점화식 구현)
```

#### 분할 정복(Divide & Conquer)
- 재귀 호출을 이용하여 큰 문제를 작은 문제로 나누어 해결하는 방법
- 재귀 호출을 이용해 Top-Down 형식으로 구현
```python
def sum_all(x):
    if len(x) == 1: # 종료조건 1
        return x[0]

    if len(x) == 0: # 종료조건 2
        return 0
    
    mid = len(x) // 2
    
    return sum_all(x[:mid]) + sum_all(x[mid:])
```

#### 재귀 호출의 한계
- 여러 번 재귀 호출이 발생하는 경우, 기하급수적으로 호출 횟수가 증가
    - 함수 호출 스택(Function call stack) 크기에 제한이 있어, 일정 횟수 이상 호출이 불가하다.
- 실질적인 계산에 필요한 연산보다, 함수 호출에 의한 Overhead가 발생한다.

#### 반복 구현
- 종료 조건을 초기값(initial value)로 하며, Bottom-Up으로 구현
```python
def fibonacci(n):
    fn_1, fn = 0,1 #초기값 설정
    
    if n == 0:
        return fn_1
    if n == 1:
        return fn
    
    for i in range(2, n+1): # 반복문 구현
        fn_1, fn = fn, fn_1+fn

    return fn
```

#### Tail Recursion
(파이썬 미지원)

- 재귀 함수에서, 재귀 호출이 마지막에 단 한번 수행되는 것을 의미
- 컴파일러에서 Tail Recursion 최적화를 지원하는 경우, 함수 호출 스택을 재활용
- 컴파일러에서 최적화를 지원하지 않으면 적용 불가(Python 미지원)

### 2. 정렬 알고리즘
#### 정렬(Sorting)
- 특정 값을 기준으로 데이터를 순서대로 배치하는 방법
- 정렬 알고리즘 조건
    - 정렬 알고리즘의 출력 :  입력을 재배열 하여 만든 순열
    - 오름차순(이전 원소는 다음 원소보다 작지 않음)
- 점근 표기법, 분할 정복 알고리즘(합병정렬/퀵정렬), 최악-최선-평균

#### 정렬 알고리즘의 주요 구분
- 제자리 알고리즘(In-place algorithm) : 알고리즘 수행에 메모리가 𝑂(㏒𝑁) 이하로 사용되는 알고리즘
- 안정 알고리즘(Stable algorithm) : 정렬 기준이 동일한 값이 정렬 전후에 순서가 유지되는 알고리즘

#### 다양한 정렬 알고리즘
- 구현 난이도 쉬움, 속도 느림
    - 버블 정렬, 삽입 정렬, 선택 정렬
- 구현 난이도 조금 더 어려움, 속도 빠름
    - 합병 정렬, 힙 정렬, 퀵 정렬, 트리 정렬
- 하이브리드 정렬
    - 팀정렬, 블록 병합 정렬, 인트로 정렬
- 기타 정렬 알고리즘
    - 기수 정렬, 카운팅 정렬, 셀 정렬, 보고 정렬

#### 버블 정렬(Bubble sort)
- 인접한 두 원소를 검사하여 자리를 교체하는 단순한 정렬 알고리즘
- 공간 복잡도 : 𝑂(1)
- 시간 복잡도 : 최악 - 𝑂(𝑁²) 최선 - 𝑂(𝑁) 평균 - 𝑂(𝑁²)
- #in-place, #Stable
- 과정 : 연속된 2개 비교 -> 그 다음 2개 비교 -> ~~~
- 구현
```python
def bubble_sort(x):
    length = len(x) - 1
    for i in range(length):
        swapped = False
        for j in range(length-i):
            if x[j] > x[j+1]:
                swapped = True
                x[j], x[j+1] = x[j+1], x[j]
            if swapped is False: # 이 조건이 있어야 최전의 경우 O(N) 으로 동작
                break
    return x
```

#### 삽입 정렬(Insertion sort)
- 앞의 데이터를 정렬 해가면서 뒤쪽의 데이터를 적절한 위치에 삽입
- 공간 복잡도 : 𝑂(1)
- 시간 복잡도 : 최악 - 𝑂(𝑁²) 최선 - 𝑂(𝑁) 평균 - 𝑂(𝑁²)
- #in-place, #Stable
- 과정 : 맨 앞 데이터 정렬 가정, n-1 개 미정렬 -> 한개씩 순차적으로 정렬 진행
- 구현
```python
def insertion_sort(x):
    for i in range(1, len(x)): # 정렬된 영역이 1씩 증가
        j = i - 1 # 0 ~ j 가 정렬된 영역
        key = x[i] # x[i]를 왼쪽으로 한칸씩 옮기면서 제자리 찾기
        while x[j] > key and j >= 0:
            x[j+1] = x[j]
            j = j - 1
        x[j+1] = key
    return x
```

#### 선택 정렬(Selection sort)
- 최소값을 찾아서 맨 앞으로 정렬하는 방식
- 공간 복잡도 : 𝑂(1)
- 시간 복잡도 : 최악 - 𝑂(𝑁²) 최선 - 𝑂(𝑁²)(매번 찾아야 함) 평균 - 𝑂(𝑁²)
- #in-place
- 구현
```python
def selection_sort(x):
    length = len(x)
    for i in range(length-1):
        index_min = i
        for j in range(i+1, length):
            if x[index_min] > x[j]:
                index_min = j
        x[i], x[index_min] = x[index_min], x[i]
    return x
```

#### 합병 정렬(Merge sort)
- 배열의 길이가 1이 될 때 까지 이분할 하고, 인접한 배열끼리 합병하면서 정렬하는 알고리즘
- 공간 복잡도 : 𝑂(𝑁)
- 시간 복잡도 : 최악 - 𝑂(𝑁log𝑁) 최선 - 𝑂(𝑁log𝑁) 평균 - 𝑂(𝑁log𝑁)
-  #Stable
- 과정 : 데이터를 쪼갬 -> 계속 쪼갬(길이가 1인 배열까지) -> 그 위단으로 정렬(각각 정렬 되어있는 상태에서 비교 - 작은 값 정렬 후 인덱스 옮겨 비교 진행)
- 구현
```python
def merge_sort(x, low = 0, high = -1, arr = None):
    if arr is None:
        arr = [0] * len(x) # 메모리를 미리 만듬

    if high == -1:
        high = len(x) - 1
    
    if low >= high: # 탈출 조건
        return
    
    mid = (low + high) // 2
    merge_sort(x, low, mid, arr)
    merge_sort(x, mid + 1, high, arr)

    i, j = low, mid + 1
    for k in range(low, high+1):
        if j > high:
            arr[k] = x[i]
            i += 1
        elif i > mid:
            arr[k] = x[j]
            j += 1
        else:
            arr[k] = x[j]
            j += 1
    x[low:high+1] = arr[low:high+1]
```

#### 퀵 정렬(Quick sort)
- 임의의 값(pivot)을 정해, 그 값을 기준으로 좌우로 나누어 정렬하는 알고리즘. Pivot의 선택에 의해 알고리즘 성능이 크게 달라질 수 있음.
- 공간 복잡도 : 𝑂(log𝑁)
- 시간 복잡도 : 최악 - 𝑂(𝑁²) 최선 - 𝑂(𝑁log𝑁) 평균 - 𝑂(𝑁log𝑁)
-  #In-place
- 과정 : 임의의 값 -> 대소 2개 그룹으로 분할 -> 그룹 내 임의의 값 지정 -> ~~~
- 구현
```python
# easy
def quick_sort(x):
    if len(x) <2 :
        return x
    left = []
    right = []
    pivot = x[len(x) // 2]

    for el in x:
        if el < pivot:
            left.append(el)
        else:
            right.append(el)
    return quick_sort(left) + [pivot] + quick_sort(right)

# hard
def quick_sort(arr):
    def sort(low, high):
        if high <= low:
            return
        mid = partition(low, high)
        sort(low, mid-1)
        sort(mid, high)

    def partition(low, high):
        pivot = arr[(low + high) // 2]
        while low <= high:
            while arr[low] < pivot:
                low += 1
            while arr[high] > pivot:
                high -= 1
            if low <= high:
                arr[low], arr[high] = arr[high], arr[low]
                low, high = low+1, high-1
        return low
    return sort(0, len(arr)-1)
```

### 3. 이진 탐색
#### 탐색 알고리즘(Search algorithms)
- 자료구조에서 원하는 조건에 맞는 자료를 찾는 것
- 선형 자료구조의 경우, 크게 세 가지 알고리즘이 있다.
    - 정렬되지 않은 자료 → 선형 탐색 𝑂(𝑁)
    - 정렬된 자료 → 이진 탐색 𝑂(log𝑁)
    - 해싱된 자료 → 해시 탐색

#### 선형 탐색 (Linear scarch)
- 가장 단순한 탐색방법(= 순차 탐색(Sequential search))
- 순서대로 하나씩 비교하기 때문에, 시간 복잡도는 𝑂(𝑁)

#### 이진 탐색 (Binary search)
- 정렬된 자료의 탐색에 최적화된 알고리즘(= 이분탐색)
- 탐색 범위를 절반씩 줄여가기 때문에, 시간 복잡도는 𝑂(log𝑁)

### 4. 투포인터(Two pointers)
- 배열에서 두개의 포인터(인덱스)를 사용하여 원하는 결과를 얻는 방법

- 두 개 포인터의 배치 방법
    - 같은 방향에서 시작 : 첫 번쨰 원소에 둘다 배치
    - 서로 다른 방향에서 시작 : 첫 번쨰 원소와 마지막 원소에 배치
- 다중 for 문의 복잡도를 좀더 선형적으로 풀 수 있음
    - ex) 범위를 다루는 이중 for 문(𝑂(𝑁²)) 을 𝑂(𝑁)으로 해결

- 투 포인터 예시
    - 아래 베열에서 부분합이 9가 되는 구간을 찾는 방법
    - 기존 단순 for 문 이용 방법
    - 125372432 -> i - 0 ~ N-1 , j - i ~ N-1
    - 포인터가 같은부분에 있다가 부분합보다 작으면 하나가 올라가고 , 크면 다른 포인터가 올라가는 형식!
- 알고리즘 시간 복잡도 : 𝑂(𝑁)

### 5. 탐욕 알고리즘
#### 탐욕 알고리즘(Greedy algorithms)
- 매 순간 현재 기준으로 최선의 답을 선택해 나가는 기법
	- 빠르게 근사치를 계산할 수 있다.
	- 결과적으로 최적해가 아닐 수 있음.
- 탐욕 알고리즘의 결과가 최적해 인 경우를 알아야 함.

#### 활동 선택 문제(Activity selection problem)
- N개의 활동과 각 활동의 시작/종료 시간이 주어졌을 때, 한 사람이 최대한 많이 할 수 있는 활동의 수 구하기
- 활동을 종료 시간 기준으로 오름차순 정렬
- 먼저 종료되는 활동부터 그리디하게 선택 → 문제 조건에 따라 시간이 겹치는 경우 제외

#### 거스름돈 문제
- 동전의 개수가 가장 적게 거스름돈을 돌려주는 문제
- 잔돈 : 890원 / 동전 종료 : 10,50,100,500 → 큰 동전부터 개수 계산
- 동전의 종류가 배수로 증가자히 않을 경우, 그리디 알고리즘이 최적해가 아닐 수 있음
	- → 동적계획법으로 해결
	
#### 그리디 알고리즘 최적해 조건
- 그리디 알고리즘은 빠르지만 최적해를 보장하지는 못함
- 아래 두 가지 조건에 해당하는 경우 적용 가능
	- 탐욕적 선택 특성(Greedy choice property)
		: 지금 선택이 다음 선택에 영향을 주지 않음.
	- 최적 부분 구조(Optimal substructure)
		: 전체 문제의 최적해는 부분 문제의 최적해로 이루어짐.

### 6. 분할 정복 이론
#### 분할 정복(Divide and conquer)
- 큰 문제를 작은 부분 문제로 나누어 해결하는 방법
	- 합병정렬, 퀵정렬, 이진 탐색 
- 분할 정복 과정
	1. 문제를 하나 이상의 부분 문제(sub-problem)로 분할
	2. 부분 문제를 각각 해결
	3. 부분 문제의 해답을 통합하여 원래 문제를 해결
- 장점
	- 문제를 나누어 처리해 어려운 문제 해결 가능
	- 병렬 처리에 적합한 계산 구조
- 단점
	- 메모리를 많이 사용(재귀 호출 구조)
- 예시
	- 최대값 찾기 : 구간을 mid 기준 계속 분할 → 길이가 1인 배열에서 두개씩 비교해서 최대값 찾기
	```python
	def get_max(arr, left, right):
		if left == right:
			return arr[left]
		
		mid = (left + right) // 2
		left = get_max(arr, left, mid)
		right = get_max(arr, mid+1, right)
		
		return left if left > right else right
	```

## 심화 알고리즘
### 1. 동적 계획법(Dynamic Programming)
- 큰 부분을 부분 문제로 나눈 후 답을 찾아가는 과정에서, 계산된 결과를 기록하고 재활용하며 문제의 답을 구하는 방식
- 중간 계산 결과를 기록하기 위한 메모리가 필요
- 한 번 계산한 부분을 다시 계산하지 않아 속도가 빠름

- 분할 정복과의 차이
    - 분할 정복은 부분 문제가 중복되지 않음.
    - DP 는 부분 문제가 중복되어 재활용에  사용
- 그리디 알고리즘과의 차이
    - 그리디 알고리즘은 순간의 최선을 구하는 방식 -> 특정 조건에서만 최적해
    - DP 는 모든 방법을 확인 후 최적해 구하는 방식 -> 항상 최적해 보장

- 분류
    - 타뷸레이션(Tabulation, tabularization)
        - Bottom-Up 접근
        - 작은 하위 문제부터 풀면서 올라감
        - 모두 계산하면서 차례대로 진행
        - 단점 : 필요없는 연산을 함.
    - 메모이제이션(Memoization)
        - Top-Down 접근
        - 큰 문제에서 하위 문제를 확인해가며 진행
        - 계산이 필요한 순간 계산하며 진행

- 예시
    - 피보나치 수열(Top-Down)
        ```python
        fibo = dict()
        fibo[0] = 0 # 재귀 종료조건 / 반복 초기값
        fibo[1] = 1

        def fibonacci(n):
            if n in fibo:
                return fibo[n]
            res = fibonacci(n-1) + fibonacci(n-2)
            fibo[n] = res
            return res
        ```
    - 피보나치 수열(Bottom-Up)
        ```python
        def fibonacci(n):
            fibo = [None] * (n + 1)
            fibo[0], fibo[1] = 0, 1

            for i in range(2, n + 1):
                fibo[i] = fibo[i - 1] + fibo[i - 2]
            
            return fibo[n]
        ```

### 2. 백 트래킹(Backtracking)
- 트리의 모든 노드를 탐색하는 과정(DFS)에서, 유망하지 않은 쪽은 더이상 탐색하지 않는 방법

- 용어
    - 유망함(Promising) : 해가 될 가능성이 있는 경우 유망하다고 함.
    - 가지치기(Pruning) : 해가 될 가능성이 없는 경우 해당 노드와 그 자식 노드를 재외하는 것
    - 백트래킹(Backtracking) : 유망하지 않은 쪽으로 가지 않고 부모 노드로 되돌아 오는 것

- N-Queen
    - N x N 체스판에 N개의 퀸이 서로 위협적이지 않게 배치하는 경우의 수 문제
    - N개를 모두 배치하기 전에 하나씩 배치하면서 유망하지 않은 경우의 수 배제